# ConvNet applied on CIFAR-10 dataset, with no data augmentation.

command = Train:Eval

precision = "float"; traceLevel = 1 ; deviceId = "auto"

rootDir = "." ; dataDir = "$rootDir$/../Data/4dTo2d/zt" ;
outputDir = "$rootDir$/../Data/4dTo2d/zt/Output" ;

modelPath = "$outputDir$/Models/ConvNet"


Train = {
    action = "train"

    BrainScriptNetworkBuilder = {
        imageShape = 18:100:1
        labelDim = 2

        featMean = 128
        featScale = 1/256
        Normalize{m,f} = x => f .* (x - m)

        model = Sequential (
            #Normalize {featMean, featScale} :
            ConvolutionalLayer {64, (3:3), pad = true} : ReLU : 
			  MaxPoolingLayer {(3:3), stride = (1:2)} :
            ConvolutionalLayer {64, (3:3), pad = true} : ReLU : 
              MaxPoolingLayer {(3:3), stride = (1:2)} :
            ConvolutionalLayer {64, (3:3), pad = true} : ReLU : 
            ConvolutionalLayer {64, (3:3), pad = true} : ReLU : 
              MaxPoolingLayer {(3:3), stride = (2:2)} :
			ConvolutionalLayer {64, (3:3), pad = true} : ReLU : 
              MaxPoolingLayer {(3:3), stride = (2:2)} :
            DenseLayer {256} : ReLU : Dropout : 
            DenseLayer {128} : ReLU : Dropout : 
            LinearLayer {labelDim}
        )

        # inputs
        features = Input {imageShape}
        labels   = Input {labelDim}

        # apply model to features
        z = model (features)

        # connect to system
        ce       = CrossEntropyWithSoftmax     (labels, z)
        errs     = ClassificationError         (labels, z)
        top5Errs = ClassificationError         (labels, z, topN=5)  # only used in Eval action

        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)  # top5Errs only used in Eval
        outputNodes     = (z)
    }

    SGD = {
        epochSize = 0
        minibatchSize = 64

        learningRatesPerSample = 0.0015625*10:0.00046875*10:0.00015625*10:0.000046875
        momentumAsTimeConstant = 0*20:607.44
        maxEpochs = 1000
        L2RegWeight = 0.002
        dropoutRate = 0*5:0.5

        numMBsToShowResult = 100
    }

    reader = {
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/TrainData.txt"
        randomize = true
        keepDataInMemory = true     # cache all data in memory 	 
        input = {
            features = { dim = 1800 ; format = "dense" }
            labels   = { dim = 2 ;   format = "dense" }
        }
    }
}

# Eval action
Eval = {
    action = "eval"
    minibatchSize = 16
    evalNodeNames = errs:top5Errs  # also test top-5 error rate
    reader = {
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/TestData.txt"
        input = {
            features = { dim = 1800 ; format = "dense" }
            labels   = { dim = 2 ;   format = "dense" }
        }
    }
}
