# ConvNet applied on CIFAR-10 dataset, with no data augmentation.

command = Train #:Eval

precision = "float"; traceLevel = 1 ; deviceId = "auto"
profilerEnabled = true
parallelTrain = true

rootDir = "/home/woody/capn/mppi027h/km3net" ; dataDir = "$rootDir$/Data" ;
outputDir = "$rootDir$/Output" ;

modelPath = "$outputDir$/Models/ConvNet"


Train = {
    action = "train"

    BrainScriptNetworkBuilder = {
        imageShape = 11:11:18:50:1
        labelDim = 2

        featMean = 128
        featScale = 1/256
        Normalize{m,f} = x => f .* (x - m)

        model = Sequential (
            #Normalize {featMean, featScale} :
            ConvolutionalLayer {4, (3:3:3:3), pad = true} : ReLU :  
			  MaxPoolingLayer {(2:2:2:4), stride = (2:2:2:4), pad = true} :	#(6:6:9:25)
			ConvolutionalLayer {32, (3:3:3:3), pad = true} : ReLU : 
			ConvolutionalLayer {32, (3:3:3:3), pad = true} : ReLU : 
			  MaxPoolingLayer {(1:1:1:2), stride = (1:1:1:2)} :  			#(6:6:9:12)
			ConvolutionalLayer {32, (3:3:3:3), pad = true} : ReLU : 
			ConvolutionalLayer {32, (3:3:3:3), pad = true} : ReLU : 
			  MaxPoolingLayer {(2:2:3:2), stride = (2:2:3:2)} : 			#(3:3:3:6)
			ConvolutionalLayer {128, (3:3:3:3), pad = true} : ReLU : 
			ConvolutionalLayer {128, (3:3:3:3), pad = true} : ReLU : 
			  MaxPoolingLayer {(1:1:1:2), stride = (1:1:1:2)} :				#(3:3:3:3)
			
			  
			            
            DenseLayer {256} : ReLU : Dropout : 
            DenseLayer {128} : ReLU : Dropout : 
            LinearLayer {labelDim}
        )

        # inputs
        features = Input {imageShape}
        labels   = Input {labelDim}

        # apply model to features
        z = model (features)

        # connect to system
        ce       = CrossEntropyWithSoftmax     (labels, z)
        errs     = ClassificationError         (labels, z)
        top5Errs = ClassificationError         (labels, z, topN=5)  # only used in Eval action

        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)  # top5Errs only used in Eval
        outputNodes     = (z)
    }

    SGD = {
        epochSize = 0
        minibatchSize = 32

        learningRatesPerSample = 0.0015625*10:0.00046875*10:0.00015625*10:0.000046875
        momentumAsTimeConstant = 0*20:607.44
        maxEpochs = 50
        L2RegWeight = 0.002
        dropoutRate = 0*5:0.5

        numMBsToShowResult = 100
		
		ParallelTrain = [
			parallelizationMethod = BlockMomentumSGD
			distributedMBReading = true
			syncPerfStats = 5
			BlockMomentumSGD=[
				syncPeriod = 120000
				resetSGDMomentum = true
				useNesterovMomentum = true
			]
		]
    }

    reader = {
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/TrainData.txt"
        randomize = true
        keepDataInMemory = false     # cache all data in memory 	 
        input = {
            features = { dim = 108900 ; format = "dense" }
            labels   = { dim = 2 ;   format = "dense" }
        }
    }
}

# Eval action
Eval = {
    action = "eval"
    minibatchSize = 16
    evalNodeNames = errs:top5Errs  # also test top-5 error rate
    reader = {
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/TestData.txt"
        input = {
            features = { dim = 108900 ; format = "dense" }
            labels   = { dim = 2 ;   format = "dense" }
        }
    }
}
